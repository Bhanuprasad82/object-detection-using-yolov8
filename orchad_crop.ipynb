{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UBZZ8VsuplLi"
      },
      "outputs": [],
      "source": [
        "!pip install ultralytics"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "m5kznDHfHI7E",
        "outputId": "cd3bf0f7-3a70-4c6a-b6e6-feb20af21d99"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "\n",
        "from google.colab import drive\n",
        "\n",
        "drive.mount('/content/gdrive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0G9iZGiyHbth",
        "outputId": "fc5cb278-105b-4a48-f59f-78b73af9b0df"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mounted at /content/gdrive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount(\"/content/gdrive\", force_remount=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tFfEp3o6LHid"
      },
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "zsxylKPzHpYd"
      },
      "outputs": [],
      "source": [
        "ROOT_DIR = '\\content\\gdrive\\MyDrive\\\\orchad-crop'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "roDUmKuAEP9T"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "RLuu76UiH7q5"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "\n",
        "from ultralytics import YOLO"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7woLTAX6IHhl",
        "outputId": "f96371c8-f322-4a51-afcf-caa359fae35a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Downloading https://github.com/ultralytics/assets/releases/download/v8.1.0/yolov8n.pt to 'yolov8n.pt'...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 6.23M/6.23M [00:00<00:00, 122MB/s]\n"
          ]
        }
      ],
      "source": [
        "model= YOLO(\"yolov8n.pt\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "60DUjbFtMSkv",
        "outputId": "86857ab7-9601-4542-90d5-58384d338cab"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "/content/gdrive/MyDrive/orchad-crop\n"
          ]
        }
      ],
      "source": [
        "cd /content/gdrive/MyDrive/orchad-crop"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "Hd6WPmPcSTs8"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yz3Sk3kbXaBg",
        "outputId": "6c182364-45e5-4910-9328-0004c60a5cf8"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Ultralytics YOLOv8.1.22 🚀 Python-3.10.12 torch-2.1.0+cu121 CUDA:0 (Tesla T4, 15102MiB)\n",
            "\u001b[34m\u001b[1mengine/trainer: \u001b[0mtask=detect, mode=train, model=yolov8n.pt, data=/content/gdrive/MyDrive/orchad-crop/classes.yaml, epochs=100, time=None, patience=100, batch=16, imgsz=640, save=True, save_period=25, cache=False, device=None, workers=8, project=None, name=train14, exist_ok=False, pretrained=True, optimizer=auto, verbose=True, seed=0, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, multi_scale=False, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=True, source=None, vid_stride=1, stream_buffer=False, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, embed=None, show=False, save_frames=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, show_boxes=True, line_width=None, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=False, opset=None, workspace=4, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, label_smoothing=0.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.0, copy_paste=0.0, auto_augment=randaugment, erasing=0.4, crop_fraction=1.0, cfg=None, tracker=botsort.yaml, save_dir=runs/detect/train14\n",
            "Downloading https://ultralytics.com/assets/Arial.ttf to '/root/.config/Ultralytics/Arial.ttf'...\n",
            "100% 755k/755k [00:00<00:00, 27.2MB/s]\n",
            "2024-03-04 10:45:45.252479: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "2024-03-04 10:45:45.252536: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "2024-03-04 10:45:45.253936: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "Overriding model.yaml nc=80 with nc=1\n",
            "\n",
            "                   from  n    params  module                                       arguments                     \n",
            "  0                  -1  1       464  ultralytics.nn.modules.conv.Conv             [3, 16, 3, 2]                 \n",
            "  1                  -1  1      4672  ultralytics.nn.modules.conv.Conv             [16, 32, 3, 2]                \n",
            "  2                  -1  1      7360  ultralytics.nn.modules.block.C2f             [32, 32, 1, True]             \n",
            "  3                  -1  1     18560  ultralytics.nn.modules.conv.Conv             [32, 64, 3, 2]                \n",
            "  4                  -1  2     49664  ultralytics.nn.modules.block.C2f             [64, 64, 2, True]             \n",
            "  5                  -1  1     73984  ultralytics.nn.modules.conv.Conv             [64, 128, 3, 2]               \n",
            "  6                  -1  2    197632  ultralytics.nn.modules.block.C2f             [128, 128, 2, True]           \n",
            "  7                  -1  1    295424  ultralytics.nn.modules.conv.Conv             [128, 256, 3, 2]              \n",
            "  8                  -1  1    460288  ultralytics.nn.modules.block.C2f             [256, 256, 1, True]           \n",
            "  9                  -1  1    164608  ultralytics.nn.modules.block.SPPF            [256, 256, 5]                 \n",
            " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
            " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 12                  -1  1    148224  ultralytics.nn.modules.block.C2f             [384, 128, 1]                 \n",
            " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
            " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 15                  -1  1     37248  ultralytics.nn.modules.block.C2f             [192, 64, 1]                  \n",
            " 16                  -1  1     36992  ultralytics.nn.modules.conv.Conv             [64, 64, 3, 2]                \n",
            " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 18                  -1  1    123648  ultralytics.nn.modules.block.C2f             [192, 128, 1]                 \n",
            " 19                  -1  1    147712  ultralytics.nn.modules.conv.Conv             [128, 128, 3, 2]              \n",
            " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 21                  -1  1    493056  ultralytics.nn.modules.block.C2f             [384, 256, 1]                 \n",
            " 22        [15, 18, 21]  1    751507  ultralytics.nn.modules.head.Detect           [1, [64, 128, 256]]           \n",
            "Model summary: 225 layers, 3011043 parameters, 3011027 gradients, 8.2 GFLOPs\n",
            "\n",
            "Transferred 319/355 items from pretrained weights\n",
            "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir runs/detect/train14', view at http://localhost:6006/\n",
            "Freezing layer 'model.22.dfl.conv.weight'\n",
            "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks with YOLOv8n...\n",
            "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed ✅\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /content/gdrive/MyDrive/orchad-crop/train/labels.cache... 177 images, 3 backgrounds, 0 corrupt: 100% 180/180 [00:00<?, ?it/s]\n",
            "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01), CLAHE(p=0.01, clip_limit=(1, 4.0), tile_grid_size=(8, 8))\n",
            "\u001b[34m\u001b[1mval: \u001b[0mScanning /content/gdrive/MyDrive/orchad-crop/val/labels.cache... 12 images, 0 backgrounds, 0 corrupt: 100% 12/12 [00:00<?, ?it/s]\n",
            "Plotting labels to runs/detect/train14/labels.jpg... \n",
            "\u001b[34m\u001b[1moptimizer:\u001b[0m 'optimizer=auto' found, ignoring 'lr0=0.01' and 'momentum=0.937' and determining best 'optimizer', 'lr0' and 'momentum' automatically... \n",
            "\u001b[34m\u001b[1moptimizer:\u001b[0m AdamW(lr=0.002, momentum=0.9) with parameter groups 57 weight(decay=0.0), 64 weight(decay=0.0005), 63 bias(decay=0.0)\n",
            "\u001b[34m\u001b[1mTensorBoard: \u001b[0mmodel graph visualization added ✅\n",
            "Image sizes 640 train, 640 val\n",
            "Using 2 dataloader workers\n",
            "Logging results to \u001b[1mruns/detect/train14\u001b[0m\n",
            "Starting training for 100 epochs...\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "      1/100      2.28G      1.085      2.462      1.538         15        640: 100% 12/12 [00:31<00:00,  2.66s/it]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 1/1 [00:03<00:00,  3.83s/it]\n",
            "                   all         12         12    0.00333          1      0.941      0.726\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "      2/100      2.27G     0.8055      1.274       1.31          8        640: 100% 12/12 [00:14<00:00,  1.23s/it]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 1/1 [00:00<00:00,  2.78it/s]\n",
            "                   all         12         12      0.452       0.75      0.656      0.399\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "      3/100      2.27G     0.7895      1.135      1.308         12        640: 100% 12/12 [00:13<00:00,  1.12s/it]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 1/1 [00:00<00:00,  2.81it/s]\n",
            "                   all         12         12      0.801      0.671      0.924      0.671\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "      4/100      2.27G     0.8334      1.068      1.286          8        640: 100% 12/12 [00:14<00:00,  1.21s/it]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 1/1 [00:00<00:00,  4.90it/s]\n",
            "                   all         12         12      0.729      0.667      0.725      0.604\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "      5/100      2.28G      0.783     0.9719       1.26         11        640: 100% 12/12 [00:14<00:00,  1.21s/it]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 1/1 [00:00<00:00,  6.48it/s]\n",
            "                   all         12         12      0.995          1      0.995      0.704\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "      6/100      2.28G     0.8014     0.9295      1.264         12        640: 100% 12/12 [00:15<00:00,  1.31s/it]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 1/1 [00:00<00:00,  4.91it/s]\n",
            "                   all         12         12      0.986          1      0.995      0.819\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "      7/100      2.28G     0.7526      0.867      1.229          9        640: 100% 12/12 [00:14<00:00,  1.18s/it]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 1/1 [00:00<00:00,  4.98it/s]\n",
            "                   all         12         12      0.934      0.917      0.955      0.766\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "      8/100      2.28G     0.7609     0.8548      1.216         13        640: 100% 12/12 [00:12<00:00,  1.03s/it]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 1/1 [00:00<00:00,  6.23it/s]\n",
            "                   all         12         12      0.969          1      0.995      0.893\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "      9/100      2.28G     0.7858     0.8589      1.254         12        640: 100% 12/12 [00:13<00:00,  1.15s/it]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 1/1 [00:00<00:00,  4.93it/s]\n",
            "                   all         12         12      0.965          1      0.995      0.826\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "     10/100      2.28G     0.7802     0.8215       1.23         11        640: 100% 12/12 [00:12<00:00,  1.02s/it]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 1/1 [00:00<00:00,  5.29it/s]\n",
            "                   all         12         12      0.599      0.871      0.729      0.477\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "     11/100      2.28G     0.7772     0.8386      1.257         13        640: 100% 12/12 [00:14<00:00,  1.23s/it]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 1/1 [00:00<00:00,  5.92it/s]\n",
            "                   all         12         12      0.895          1      0.995      0.892\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "     12/100      2.28G      0.749     0.7653      1.225          8        640: 100% 12/12 [00:13<00:00,  1.12s/it]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 1/1 [00:00<00:00,  6.24it/s]\n",
            "                   all         12         12      0.732       0.75      0.834      0.698\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "     13/100      2.28G     0.7066     0.6965      1.193         15        640: 100% 12/12 [00:13<00:00,  1.16s/it]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 1/1 [00:00<00:00,  4.88it/s]\n",
            "                   all         12         12      0.991          1      0.995      0.838\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "     14/100      2.28G     0.7247     0.6883      1.178          8        640: 100% 12/12 [00:14<00:00,  1.17s/it]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 1/1 [00:00<00:00,  2.82it/s]\n",
            "                   all         12         12      0.983          1      0.995      0.845\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "     15/100      2.28G      0.764     0.7073      1.212         13        640: 100% 12/12 [00:11<00:00,  1.05it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 1/1 [00:00<00:00,  3.26it/s]\n",
            "                   all         12         12      0.993          1      0.995      0.773\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "     16/100      2.28G     0.7303      0.662       1.19         12        640: 100% 12/12 [00:12<00:00,  1.05s/it]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 1/1 [00:00<00:00,  3.00it/s]\n",
            "                   all         12         12      0.856      0.993      0.977      0.736\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "     17/100      2.28G     0.6899     0.6374      1.175         13        640: 100% 12/12 [00:14<00:00,  1.23s/it]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 1/1 [00:00<00:00,  3.24it/s]\n",
            "                   all         12         12      0.994          1      0.995      0.871\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "     18/100      2.28G     0.7055     0.6289      1.177         13        640: 100% 12/12 [00:09<00:00,  1.22it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 1/1 [00:00<00:00,  4.78it/s]\n",
            "                   all         12         12      0.994          1      0.995      0.832\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "     19/100      2.28G     0.7052     0.6373      1.179         12        640: 100% 12/12 [00:11<00:00,  1.00it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 1/1 [00:00<00:00,  3.26it/s]\n",
            "                   all         12         12      0.995          1      0.995      0.894\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "     20/100      2.28G     0.6928     0.5842      1.154          9        640: 100% 12/12 [00:10<00:00,  1.17it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 1/1 [00:00<00:00,  3.52it/s]\n",
            "                   all         12         12      0.989          1      0.995      0.844\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "     21/100      2.28G     0.7307     0.6011      1.197          8        640: 100% 12/12 [00:14<00:00,  1.19s/it]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 1/1 [00:00<00:00,  3.69it/s]\n",
            "                   all         12         12      0.965          1      0.995      0.845\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "     22/100      2.28G     0.6956     0.5528      1.164         11        640: 100% 12/12 [00:14<00:00,  1.19s/it]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 1/1 [00:00<00:00,  6.80it/s]\n",
            "                   all         12         12      0.986      0.917      0.989      0.795\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "     23/100      2.28G     0.6811     0.5761      1.159          7        640: 100% 12/12 [00:12<00:00,  1.01s/it]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 1/1 [00:00<00:00,  5.02it/s]\n",
            "                   all         12         12      0.843      0.917      0.979      0.769\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "     24/100      2.28G     0.7072     0.5469      1.168         12        640: 100% 12/12 [00:15<00:00,  1.28s/it]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 1/1 [00:00<00:00,  6.07it/s]\n",
            "                   all         12         12      0.832      0.917      0.894      0.628\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "     25/100      2.28G     0.6385     0.5592      1.142         10        640: 100% 12/12 [00:12<00:00,  1.01s/it]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 1/1 [00:00<00:00,  5.63it/s]\n",
            "                   all         12         12          1      0.992      0.995      0.763\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "     26/100      2.28G     0.6224     0.5179      1.122         12        640: 100% 12/12 [00:14<00:00,  1.19s/it]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 1/1 [00:00<00:00,  5.85it/s]\n",
            "                   all         12         12      0.983          1      0.995      0.843\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "     27/100      2.28G     0.6989     0.5801      1.204          7        640: 100% 12/12 [00:13<00:00,  1.08s/it]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 1/1 [00:00<00:00,  4.40it/s]\n",
            "                   all         12         12      0.991          1      0.995      0.877\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "     28/100      2.28G     0.6495     0.5351      1.151         13        640: 100% 12/12 [00:12<00:00,  1.07s/it]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 1/1 [00:00<00:00,  6.79it/s]\n",
            "                   all         12         12      0.979          1      0.995      0.882\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "     29/100      2.28G     0.6533     0.5011      1.151         12        640: 100% 12/12 [00:12<00:00,  1.04s/it]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 1/1 [00:00<00:00,  5.95it/s]\n",
            "                   all         12         12       0.98          1      0.995       0.85\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "     30/100      2.28G     0.6573     0.5355      1.126         10        640: 100% 12/12 [00:14<00:00,  1.17s/it]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 1/1 [00:00<00:00,  5.17it/s]\n",
            "                   all         12         12      0.987          1      0.995      0.873\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "     31/100      2.28G     0.6225     0.4897      1.117         11        640: 100% 12/12 [00:12<00:00,  1.04s/it]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 1/1 [00:00<00:00,  5.75it/s]\n",
            "                   all         12         12      0.985          1      0.995      0.845\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "     32/100      2.28G     0.6467     0.4915      1.158         11        640: 100% 12/12 [00:14<00:00,  1.17s/it]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 1/1 [00:00<00:00,  4.08it/s]\n",
            "                   all         12         12      0.987          1      0.995      0.861\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "     33/100      2.28G     0.6485     0.4923      1.151          8        640: 100% 12/12 [00:13<00:00,  1.10s/it]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 1/1 [00:00<00:00,  6.34it/s]\n",
            "                   all         12         12      0.988          1      0.995      0.881\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "     34/100      2.28G     0.6421     0.4838      1.125         10        640: 100% 12/12 [00:12<00:00,  1.08s/it]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 1/1 [00:00<00:00,  5.44it/s]\n",
            "                   all         12         12      0.966          1      0.995      0.844\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "     35/100      2.28G     0.6281     0.4942      1.169          9        640: 100% 12/12 [00:13<00:00,  1.14s/it]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 1/1 [00:00<00:00,  5.09it/s]\n",
            "                   all         12         12      0.984          1      0.995      0.852\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "     36/100      2.28G     0.6346     0.4728      1.122         12        640: 100% 12/12 [00:12<00:00,  1.01s/it]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 1/1 [00:00<00:00,  8.63it/s]\n",
            "                   all         12         12      0.993          1      0.995      0.859\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "     37/100      2.28G     0.6108     0.4542      1.115         15        640: 100% 12/12 [00:12<00:00,  1.06s/it]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 1/1 [00:00<00:00,  5.26it/s]\n",
            "                   all         12         12      0.995          1      0.995      0.876\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "     38/100      2.28G     0.6022     0.4673      1.124         11        640: 100% 12/12 [00:11<00:00,  1.02it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 1/1 [00:00<00:00,  5.95it/s]\n",
            "                   all         12         12      0.994          1      0.995      0.875\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "     39/100      2.28G     0.5908     0.4246      1.099          8        640: 100% 12/12 [00:14<00:00,  1.21s/it]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 1/1 [00:00<00:00,  5.90it/s]\n",
            "                   all         12         12      0.993          1      0.995      0.894\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "     40/100      2.28G     0.5757     0.4335      1.081         10        640: 100% 12/12 [00:14<00:00,  1.17s/it]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 1/1 [00:00<00:00,  6.00it/s]\n",
            "                   all         12         12      0.995          1      0.995      0.907\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "     41/100      2.28G     0.5921     0.4341      1.093         14        640: 100% 12/12 [00:12<00:00,  1.04s/it]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 1/1 [00:00<00:00,  6.26it/s]\n",
            "                   all         12         12      0.994          1      0.995      0.886\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "     42/100      2.28G     0.5765     0.4342      1.115          9        640: 100% 12/12 [00:12<00:00,  1.07s/it]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 1/1 [00:00<00:00,  5.15it/s]\n",
            "                   all         12         12      0.993          1      0.995      0.887\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "     43/100      2.28G     0.5775     0.4428      1.121          8        640: 100% 12/12 [00:13<00:00,  1.10s/it]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 1/1 [00:00<00:00,  6.23it/s]\n",
            "                   all         12         12      0.995          1      0.995      0.909\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "     44/100      2.28G     0.5675     0.4123       1.09          7        640: 100% 12/12 [00:14<00:00,  1.23s/it]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 1/1 [00:00<00:00,  3.66it/s]\n",
            "                   all         12         12      0.996          1      0.995      0.902\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "     45/100      2.28G     0.6022      0.439      1.087         10        640: 100% 12/12 [00:11<00:00,  1.07it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 1/1 [00:00<00:00,  5.70it/s]\n",
            "                   all         12         12      0.995          1      0.995      0.891\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "     46/100      2.28G     0.5952     0.4371      1.106         12        640: 100% 12/12 [00:12<00:00,  1.01s/it]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 1/1 [00:00<00:00,  5.72it/s]\n",
            "                   all         12         12      0.994          1      0.995      0.867\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "     47/100      2.28G     0.5807     0.4157      1.083          7        640: 100% 12/12 [00:11<00:00,  1.00it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 1/1 [00:00<00:00,  4.33it/s]\n",
            "                   all         12         12      0.995          1      0.995      0.902\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "     48/100      2.28G     0.5885     0.4039      1.086          9        640: 100% 12/12 [00:12<00:00,  1.08s/it]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 1/1 [00:00<00:00,  6.49it/s]\n",
            "                   all         12         12      0.995          1      0.995      0.911\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "     49/100      2.28G     0.5725     0.4125       1.06         10        640: 100% 12/12 [00:12<00:00,  1.05s/it]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 1/1 [00:00<00:00,  4.98it/s]\n",
            "                   all         12         12      0.993          1      0.995      0.898\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "     50/100      2.28G       0.58     0.4059      1.075         12        640: 100% 12/12 [00:14<00:00,  1.18s/it]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 1/1 [00:00<00:00,  6.18it/s]\n",
            "                   all         12         12      0.988          1      0.995      0.892\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "     51/100      2.28G     0.6356     0.4537      1.142         10        640: 100% 12/12 [00:11<00:00,  1.09it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 1/1 [00:00<00:00,  6.29it/s]\n",
            "                   all         12         12       0.99          1      0.995      0.861\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "     52/100      2.28G       0.57     0.4062      1.087         15        640: 100% 12/12 [00:12<00:00,  1.02s/it]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 1/1 [00:00<00:00,  5.00it/s]\n",
            "                   all         12         12      0.994          1      0.995      0.912\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "     53/100      2.28G      0.533     0.3802      1.093         11        640: 100% 12/12 [00:13<00:00,  1.10s/it]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 1/1 [00:00<00:00,  3.29it/s]\n",
            "                   all         12         12      0.994          1      0.995      0.865\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "     54/100      2.28G     0.5416     0.4048      1.086         10        640: 100% 12/12 [00:12<00:00,  1.00s/it]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 1/1 [00:00<00:00,  4.39it/s]\n",
            "                   all         12         12      0.995          1      0.995      0.932\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "     55/100      2.28G     0.5443     0.3701      1.081         11        640: 100% 12/12 [00:14<00:00,  1.17s/it]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 1/1 [00:00<00:00,  6.32it/s]\n",
            "                   all         12         12      0.995          1      0.995      0.915\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "     56/100      2.28G     0.5467     0.3974      1.085          8        640: 100% 12/12 [00:12<00:00,  1.08s/it]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 1/1 [00:00<00:00,  4.32it/s]\n",
            "                   all         12         12      0.994          1      0.995      0.906\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "     57/100      2.28G     0.5291     0.3815      1.059          6        640: 100% 12/12 [00:13<00:00,  1.11s/it]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 1/1 [00:00<00:00,  6.31it/s]\n",
            "                   all         12         12      0.993          1      0.995      0.905\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "     58/100      2.28G     0.5641     0.4055       1.08         14        640: 100% 12/12 [00:12<00:00,  1.03s/it]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 1/1 [00:00<00:00,  6.54it/s]\n",
            "                   all         12         12      0.994          1      0.995      0.903\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "     59/100      2.28G     0.5141     0.3576      1.056         15        640: 100% 12/12 [00:10<00:00,  1.12it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 1/1 [00:00<00:00,  3.37it/s]\n",
            "                   all         12         12      0.995          1      0.995       0.86\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "     60/100      2.28G     0.5438     0.3673      1.065         10        640: 100% 12/12 [00:13<00:00,  1.12s/it]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 1/1 [00:00<00:00,  3.47it/s]\n",
            "                   all         12         12      0.996          1      0.995      0.916\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "     61/100      2.28G     0.5207     0.3663      1.061          8        640: 100% 12/12 [00:12<00:00,  1.01s/it]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 1/1 [00:00<00:00,  3.03it/s]\n",
            "                   all         12         12      0.996          1      0.995      0.911\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "     62/100      2.28G     0.5233     0.3531      1.055         14        640: 100% 12/12 [00:11<00:00,  1.03it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 1/1 [00:00<00:00,  4.31it/s]\n",
            "                   all         12         12      0.996          1      0.995      0.925\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "     63/100      2.28G     0.5076     0.3591      1.037         14        640: 100% 12/12 [00:12<00:00,  1.01s/it]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 1/1 [00:00<00:00,  4.06it/s]\n",
            "                   all         12         12      0.996          1      0.995      0.925\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "     64/100      2.28G     0.4885     0.3485       1.04          9        640: 100% 12/12 [00:13<00:00,  1.10s/it]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 1/1 [00:00<00:00,  4.02it/s]\n",
            "                   all         12         12      0.996          1      0.995       0.93\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "     65/100      2.28G     0.5114     0.3511      1.041         15        640: 100% 12/12 [00:14<00:00,  1.17s/it]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 1/1 [00:00<00:00,  6.61it/s]\n",
            "                   all         12         12      0.996          1      0.995      0.946\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "     66/100      2.28G     0.4854     0.3268      1.031         11        640: 100% 12/12 [00:14<00:00,  1.17s/it]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 1/1 [00:00<00:00,  4.71it/s]\n",
            "                   all         12         12      0.995          1      0.995      0.905\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "     67/100      2.28G     0.4927     0.3401      1.048          8        640: 100% 12/12 [00:13<00:00,  1.12s/it]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 1/1 [00:00<00:00,  6.40it/s]\n",
            "                   all         12         12      0.995          1      0.995      0.917\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "     68/100      2.28G     0.5356      0.356       1.06         10        640: 100% 12/12 [00:14<00:00,  1.20s/it]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 1/1 [00:00<00:00,  5.16it/s]\n",
            "                   all         12         12      0.996          1      0.995      0.922\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "     69/100      2.28G     0.4773     0.3349      1.036         12        640: 100% 12/12 [00:11<00:00,  1.02it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 1/1 [00:00<00:00,  5.04it/s]\n",
            "                   all         12         12      0.996          1      0.995      0.929\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "     70/100      2.28G     0.5037     0.3419      1.036         15        640: 100% 12/12 [00:13<00:00,  1.11s/it]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 1/1 [00:00<00:00,  6.02it/s]\n",
            "                   all         12         12      0.996          1      0.995      0.929\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "     71/100      2.28G     0.4972     0.3408      1.045          8        640: 100% 12/12 [00:12<00:00,  1.05s/it]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 1/1 [00:00<00:00,  4.07it/s]\n",
            "                   all         12         12      0.996          1      0.995      0.935\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "     72/100      2.28G     0.4796     0.3254      1.018          8        640: 100% 12/12 [00:13<00:00,  1.12s/it]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 1/1 [00:00<00:00,  5.42it/s]\n",
            "                   all         12         12      0.996          1      0.995      0.922\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "     73/100      2.28G     0.4984     0.3336      1.033         12        640: 100% 12/12 [00:14<00:00,  1.22s/it]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 1/1 [00:00<00:00,  5.95it/s]\n",
            "                   all         12         12      0.996          1      0.995      0.916\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "     74/100      2.28G      0.502     0.3429      1.016         15        640: 100% 12/12 [00:12<00:00,  1.04s/it]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 1/1 [00:00<00:00,  7.03it/s]\n",
            "                   all         12         12      0.995          1      0.995      0.935\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "     75/100      2.28G     0.4874     0.3476       1.04         14        640: 100% 12/12 [00:13<00:00,  1.10s/it]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 1/1 [00:00<00:00,  4.60it/s]\n",
            "                   all         12         12      0.994          1      0.995      0.899\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "     76/100      2.28G     0.5298      0.375      1.069         12        640: 100% 12/12 [00:13<00:00,  1.12s/it]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 1/1 [00:00<00:00,  6.71it/s]\n",
            "                   all         12         12      0.995          1      0.995      0.907\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "     77/100      2.28G     0.5133     0.3584      1.029         11        640: 100% 12/12 [00:15<00:00,  1.25s/it]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 1/1 [00:00<00:00,  5.66it/s]\n",
            "                   all         12         12      0.995          1      0.995      0.954\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "     78/100      2.28G     0.4859     0.3585      1.037         10        640: 100% 12/12 [00:12<00:00,  1.05s/it]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 1/1 [00:00<00:00,  4.06it/s]\n",
            "                   all         12         12      0.996          1      0.995      0.942\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "     79/100      2.28G     0.4856     0.3318      1.038          9        640: 100% 12/12 [00:13<00:00,  1.11s/it]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 1/1 [00:00<00:00,  2.89it/s]\n",
            "                   all         12         12      0.996          1      0.995      0.938\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "     80/100      2.28G     0.4729     0.3239      1.039         12        640: 100% 12/12 [00:13<00:00,  1.16s/it]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 1/1 [00:00<00:00,  6.77it/s]\n",
            "                   all         12         12      0.996          1      0.995      0.936\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "     81/100      2.28G     0.4981     0.3327      1.025          9        640: 100% 12/12 [00:13<00:00,  1.13s/it]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 1/1 [00:00<00:00,  4.39it/s]\n",
            "                   all         12         12      0.996          1      0.995      0.939\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "     82/100      2.28G     0.4859     0.3123      1.026         10        640: 100% 12/12 [00:12<00:00,  1.04s/it]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 1/1 [00:00<00:00,  5.73it/s]\n",
            "                   all         12         12      0.996          1      0.995      0.933\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "     83/100      2.28G      0.481     0.3243      1.037          7        640: 100% 12/12 [00:13<00:00,  1.11s/it]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 1/1 [00:00<00:00,  4.11it/s]\n",
            "                   all         12         12      0.996          1      0.995       0.92\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "     84/100      2.28G     0.4531     0.3099      1.023         14        640: 100% 12/12 [00:13<00:00,  1.14s/it]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 1/1 [00:00<00:00,  6.61it/s]\n",
            "                   all         12         12      0.996          1      0.995      0.921\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "     85/100      2.28G     0.4811     0.3173      1.027          9        640: 100% 12/12 [00:10<00:00,  1.12it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 1/1 [00:00<00:00,  5.05it/s]\n",
            "                   all         12         12      0.996          1      0.995      0.922\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "     86/100      2.28G     0.4527     0.3243      1.012          8        640: 100% 12/12 [00:12<00:00,  1.01s/it]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 1/1 [00:00<00:00, 11.17it/s]\n",
            "                   all         12         12      0.996          1      0.995      0.929\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "     87/100      2.28G     0.4539     0.3126      1.039         10        640: 100% 12/12 [00:14<00:00,  1.18s/it]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 1/1 [00:00<00:00,  6.65it/s]\n",
            "                   all         12         12      0.996          1      0.995      0.947\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "     88/100      2.28G     0.4529     0.2984      1.001          9        640: 100% 12/12 [00:12<00:00,  1.07s/it]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 1/1 [00:00<00:00,  5.23it/s]\n",
            "                   all         12         12      0.996          1      0.995      0.945\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "     89/100      2.28G      0.441     0.2929      1.015         11        640: 100% 12/12 [00:14<00:00,  1.19s/it]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 1/1 [00:00<00:00,  5.12it/s]\n",
            "                   all         12         12      0.995          1      0.995      0.934\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "     90/100      2.28G     0.4343     0.3037      1.016          9        640: 100% 12/12 [00:13<00:00,  1.17s/it]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 1/1 [00:00<00:00,  6.13it/s]\n",
            "                   all         12         12      0.995          1      0.995      0.936\n",
            "Closing dataloader mosaic\n",
            "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01), CLAHE(p=0.01, clip_limit=(1, 4.0), tile_grid_size=(8, 8))\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "     91/100      2.28G     0.5163     0.4796      1.143          4        640: 100% 12/12 [00:31<00:00,  2.65s/it]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 1/1 [00:00<00:00,  3.97it/s]\n",
            "                   all         12         12      0.994          1      0.995      0.927\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "     92/100      2.28G     0.4139     0.2971      1.008          4        640: 100% 12/12 [00:18<00:00,  1.51s/it]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 1/1 [00:00<00:00,  6.12it/s]\n",
            "                   all         12         12      0.993          1      0.995      0.943\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "     93/100      2.28G     0.4091     0.3165      1.021          3        640: 100% 12/12 [00:11<00:00,  1.06it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 1/1 [00:00<00:00,  5.56it/s]\n",
            "                   all         12         12      0.993          1      0.995       0.96\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "     94/100      2.28G      0.396     0.2711      1.034          4        640: 100% 12/12 [00:14<00:00,  1.18s/it]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 1/1 [00:00<00:00,  9.76it/s]\n",
            "                   all         12         12      0.994          1      0.995      0.945\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "     95/100      2.28G     0.3732     0.2411     0.9885          4        640: 100% 12/12 [00:15<00:00,  1.33s/it]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 1/1 [00:00<00:00,  2.86it/s]\n",
            "                   all         12         12      0.995          1      0.995      0.923\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "     96/100      2.28G     0.3761     0.2389     0.9677          4        640: 100% 12/12 [00:12<00:00,  1.08s/it]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 1/1 [00:00<00:00,  3.98it/s]\n",
            "                   all         12         12      0.995          1      0.995      0.945\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "     97/100      2.28G     0.3847     0.2487      1.007          4        640: 100% 12/12 [00:13<00:00,  1.15s/it]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 1/1 [00:00<00:00,  5.08it/s]\n",
            "                   all         12         12      0.995          1      0.995      0.945\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "     98/100      2.28G     0.3588     0.2321     0.9742          4        640: 100% 12/12 [00:13<00:00,  1.09s/it]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 1/1 [00:00<00:00,  5.43it/s]\n",
            "                   all         12         12      0.995          1      0.995      0.945\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "     99/100      2.28G     0.3575      0.235     0.9673          4        640: 100% 12/12 [00:13<00:00,  1.11s/it]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 1/1 [00:00<00:00,  5.10it/s]\n",
            "                   all         12         12      0.995          1      0.995      0.933\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "    100/100      2.28G     0.3958     0.2535     0.9828          4        640: 100% 12/12 [00:12<00:00,  1.01s/it]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 1/1 [00:00<00:00,  5.82it/s]\n",
            "                   all         12         12      0.995          1      0.995      0.928\n",
            "\n",
            "100 epochs completed in 0.430 hours.\n",
            "Optimizer stripped from runs/detect/train14/weights/last.pt, 6.3MB\n",
            "Optimizer stripped from runs/detect/train14/weights/best.pt, 6.3MB\n",
            "\n",
            "Validating runs/detect/train14/weights/best.pt...\n",
            "Ultralytics YOLOv8.1.22 🚀 Python-3.10.12 torch-2.1.0+cu121 CUDA:0 (Tesla T4, 15102MiB)\n",
            "Model summary (fused): 168 layers, 3005843 parameters, 0 gradients, 8.1 GFLOPs\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 1/1 [00:00<00:00,  4.93it/s]\n",
            "                   all         12         12      0.993          1      0.995       0.96\n",
            "Speed: 0.3ms preprocess, 4.9ms inference, 0.0ms loss, 1.8ms postprocess per image\n",
            "Results saved to \u001b[1mruns/detect/train14\u001b[0m\n",
            "💡 Learn more at https://docs.ultralytics.com/modes/train\n"
          ]
        }
      ],
      "source": [
        "!yolo detect train data=/content/gdrive/MyDrive/orchad-crop/classes.yaml model=yolov8n.pt epochs=100 imgsz=640 batch=16 save_period=25"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cNOWGnRJXvB3"
      },
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d_f_z9AoXu-X"
      },
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L3n_S-AxXu2b"
      },
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 602
        },
        "id": "7ajiJguZIS74",
        "outputId": "9cbb900f-95b3-4604-b583-cc452d977e3c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[31m\u001b[1mrequirements:\u001b[0m Ultralytics requirement ['lapx>=0.5.2'] not found, attempting AutoUpdate...\n",
            "Collecting lapx>=0.5.2\n",
            "  Downloading lapx-0.5.5-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.7 MB)\n",
            "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 1.7/1.7 MB 11.5 MB/s eta 0:00:00\n",
            "Requirement already satisfied: Cython>=0.29.32 in /usr/local/lib/python3.10/dist-packages (from lapx>=0.5.2) (3.0.8)\n",
            "Requirement already satisfied: numpy>=1.21.6 in /usr/local/lib/python3.10/dist-packages (from lapx>=0.5.2) (1.25.2)\n",
            "Installing collected packages: lapx\n",
            "Successfully installed lapx-0.5.5\n",
            "\n",
            "\u001b[31m\u001b[1mrequirements:\u001b[0m AutoUpdate success ✅ 5.2s, installed 1 package: ['lapx>=0.5.2']\n",
            "\u001b[31m\u001b[1mrequirements:\u001b[0m ⚠️ \u001b[1mRestart runtime or rerun command for updates to take effect\u001b[0m\n",
            "\n",
            "WARNING ⚠️ Environment does not support cv2.imshow() or PIL Image.show()\n",
            "\n",
            "\n"
          ]
        },
        {
          "ename": "FileNotFoundError",
          "evalue": "No images or videos found in /content/gdrive/MyDrive/orchad-crop/classes.yaml. Supported formats are:\nimages: ('bmp', 'dng', 'jpeg', 'jpg', 'mpo', 'png', 'tif', 'tiff', 'webp', 'pfm')\nvideos: ('asf', 'avi', 'gif', 'm4v', 'mkv', 'mov', 'mp4', 'mpeg', 'mpg', 'ts', 'wmv', 'webm')",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-9-cdafd9c54ddd>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"/content/gdrive/MyDrive/orchad-crop/classes.yaml\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconf\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0miou\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.5\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshow\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/ultralytics/engine/model.py\u001b[0m in \u001b[0;36mtrack\u001b[0;34m(self, source, stream, persist, **kwargs)\u001b[0m\n\u001b[1;32m    476\u001b[0m         \u001b[0mkwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"conf\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"conf\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;36m0.1\u001b[0m  \u001b[0;31m# ByteTrack-based method needs low confidence predictions as input\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    477\u001b[0m         \u001b[0mkwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"mode\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"track\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 478\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msource\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msource\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstream\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstream\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    479\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    480\u001b[0m     def val(\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/ultralytics/engine/model.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, source, stream, predictor, **kwargs)\u001b[0m\n\u001b[1;32m    437\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mprompts\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredictor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"set_prompts\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# for SAM-type models\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    438\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredictor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_prompts\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprompts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 439\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredictor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict_cli\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msource\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msource\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mis_cli\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredictor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msource\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msource\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstream\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstream\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    440\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    441\u001b[0m     def track(\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/ultralytics/engine/predictor.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, source, model, stream, *args, **kwargs)\u001b[0m\n\u001b[1;32m    204\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstream_inference\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msource\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    205\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 206\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstream_inference\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msource\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# merge list of Result into one\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    207\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    208\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mpredict_cli\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msource\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/utils/_contextlib.py\u001b[0m in \u001b[0;36mgenerator_context\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     33\u001b[0m             \u001b[0;31m# Issuing `None` to a generator fires it up\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mctx_factory\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 35\u001b[0;31m                 \u001b[0mresponse\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgen\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     36\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     37\u001b[0m             \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/ultralytics/engine/predictor.py\u001b[0m in \u001b[0;36mstream_inference\u001b[0;34m(self, source, model, *args, **kwargs)\u001b[0m\n\u001b[1;32m    254\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# for thread-safe inference\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    255\u001b[0m             \u001b[0;31m# Setup source every time predict is called\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 256\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msetup_source\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msource\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0msource\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msource\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    257\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    258\u001b[0m             \u001b[0;31m# Check if save_dir/ label file exists\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/ultralytics/engine/predictor.py\u001b[0m in \u001b[0;36msetup_source\u001b[0;34m(self, source)\u001b[0m\n\u001b[1;32m    228\u001b[0m             \u001b[0;32melse\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    229\u001b[0m         )\n\u001b[0;32m--> 230\u001b[0;31m         self.dataset = load_inference_source(\n\u001b[0m\u001b[1;32m    231\u001b[0m             \u001b[0msource\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msource\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvid_stride\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvid_stride\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbuffer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstream_buffer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    232\u001b[0m         )\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/ultralytics/data/build.py\u001b[0m in \u001b[0;36mload_inference_source\u001b[0;34m(source, vid_stride, buffer)\u001b[0m\n\u001b[1;32m    178\u001b[0m         \u001b[0mdataset\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mLoadPilAndNumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msource\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    179\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 180\u001b[0;31m         \u001b[0mdataset\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mLoadImages\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msource\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvid_stride\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvid_stride\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    181\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    182\u001b[0m     \u001b[0;31m# Attach source types to the dataset\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/ultralytics/data/loaders.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, path, vid_stride)\u001b[0m\n\u001b[1;32m    305\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcap\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    306\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnf\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 307\u001b[0;31m             raise FileNotFoundError(\n\u001b[0m\u001b[1;32m    308\u001b[0m                 \u001b[0;34mf\"No images or videos found in {p}. \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    309\u001b[0m                 \u001b[0;34mf\"Supported formats are:\\nimages: {IMG_FORMATS}\\nvideos: {VID_FORMATS}\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: No images or videos found in /content/gdrive/MyDrive/orchad-crop/classes.yaml. Supported formats are:\nimages: ('bmp', 'dng', 'jpeg', 'jpg', 'mpo', 'png', 'tif', 'tiff', 'webp', 'pfm')\nvideos: ('asf', 'avi', 'gif', 'm4v', 'mkv', 'mov', 'mp4', 'mpeg', 'mpg', 'ts', 'wmv', 'webm')"
          ]
        }
      ],
      "source": [
        "#results = model.track(\"/content/gdrive/MyDrive/orchad-crop/classes.yaml\", conf=0.3, iou=0.5, show=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bqhf4OAELPv2",
        "outputId": "1ce4a134-3793-4526-9d8d-831b038d9e85"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Ultralytics YOLOv8.1.22 🚀 Python-3.10.12 torch-2.1.0+cu121 CUDA:0 (Tesla T4, 15102MiB)\n",
            "Model summary (fused): 168 layers, 3005843 parameters, 0 gradients, 8.1 GFLOPs\n",
            "\n",
            "video 1/1 (1/312) /content/Untitled video - Made with Clipchamp.mp4: 384x640 2 trees, 104.5ms\n",
            "video 1/1 (2/312) /content/Untitled video - Made with Clipchamp.mp4: 384x640 2 trees, 8.4ms\n",
            "video 1/1 (3/312) /content/Untitled video - Made with Clipchamp.mp4: 384x640 2 trees, 7.3ms\n",
            "video 1/1 (4/312) /content/Untitled video - Made with Clipchamp.mp4: 384x640 2 trees, 12.9ms\n",
            "video 1/1 (5/312) /content/Untitled video - Made with Clipchamp.mp4: 384x640 2 trees, 9.5ms\n",
            "video 1/1 (6/312) /content/Untitled video - Made with Clipchamp.mp4: 384x640 2 trees, 8.8ms\n",
            "video 1/1 (7/312) /content/Untitled video - Made with Clipchamp.mp4: 384x640 2 trees, 9.2ms\n",
            "video 1/1 (8/312) /content/Untitled video - Made with Clipchamp.mp4: 384x640 2 trees, 8.7ms\n",
            "video 1/1 (9/312) /content/Untitled video - Made with Clipchamp.mp4: 384x640 2 trees, 8.2ms\n",
            "video 1/1 (10/312) /content/Untitled video - Made with Clipchamp.mp4: 384x640 2 trees, 7.9ms\n",
            "video 1/1 (11/312) /content/Untitled video - Made with Clipchamp.mp4: 384x640 2 trees, 14.4ms\n",
            "video 1/1 (12/312) /content/Untitled video - Made with Clipchamp.mp4: 384x640 2 trees, 7.9ms\n",
            "video 1/1 (13/312) /content/Untitled video - Made with Clipchamp.mp4: 384x640 3 trees, 7.7ms\n",
            "video 1/1 (14/312) /content/Untitled video - Made with Clipchamp.mp4: 384x640 2 trees, 8.0ms\n",
            "video 1/1 (15/312) /content/Untitled video - Made with Clipchamp.mp4: 384x640 2 trees, 8.1ms\n",
            "video 1/1 (16/312) /content/Untitled video - Made with Clipchamp.mp4: 384x640 3 trees, 7.2ms\n",
            "video 1/1 (17/312) /content/Untitled video - Made with Clipchamp.mp4: 384x640 2 trees, 7.1ms\n",
            "video 1/1 (18/312) /content/Untitled video - Made with Clipchamp.mp4: 384x640 1 tree, 8.2ms\n",
            "video 1/1 (19/312) /content/Untitled video - Made with Clipchamp.mp4: 384x640 2 trees, 10.9ms\n",
            "video 1/1 (20/312) /content/Untitled video - Made with Clipchamp.mp4: 384x640 1 tree, 8.0ms\n",
            "video 1/1 (21/312) /content/Untitled video - Made with Clipchamp.mp4: 384x640 1 tree, 7.7ms\n",
            "video 1/1 (22/312) /content/Untitled video - Made with Clipchamp.mp4: 384x640 1 tree, 9.7ms\n",
            "video 1/1 (23/312) /content/Untitled video - Made with Clipchamp.mp4: 384x640 1 tree, 8.2ms\n",
            "video 1/1 (24/312) /content/Untitled video - Made with Clipchamp.mp4: 384x640 1 tree, 7.6ms\n",
            "video 1/1 (25/312) /content/Untitled video - Made with Clipchamp.mp4: 384x640 1 tree, 8.3ms\n",
            "video 1/1 (26/312) /content/Untitled video - Made with Clipchamp.mp4: 384x640 1 tree, 9.2ms\n",
            "video 1/1 (27/312) /content/Untitled video - Made with Clipchamp.mp4: 384x640 1 tree, 7.7ms\n",
            "video 1/1 (28/312) /content/Untitled video - Made with Clipchamp.mp4: 384x640 2 trees, 7.4ms\n",
            "video 1/1 (29/312) /content/Untitled video - Made with Clipchamp.mp4: 384x640 1 tree, 8.0ms\n",
            "video 1/1 (30/312) /content/Untitled video - Made with Clipchamp.mp4: 384x640 1 tree, 7.2ms\n",
            "video 1/1 (31/312) /content/Untitled video - Made with Clipchamp.mp4: 384x640 1 tree, 7.8ms\n",
            "video 1/1 (32/312) /content/Untitled video - Made with Clipchamp.mp4: 384x640 1 tree, 7.4ms\n",
            "video 1/1 (33/312) /content/Untitled video - Made with Clipchamp.mp4: 384x640 1 tree, 7.9ms\n",
            "video 1/1 (34/312) /content/Untitled video - Made with Clipchamp.mp4: 384x640 1 tree, 7.4ms\n",
            "video 1/1 (35/312) /content/Untitled video - Made with Clipchamp.mp4: 384x640 1 tree, 9.2ms\n",
            "video 1/1 (36/312) /content/Untitled video - Made with Clipchamp.mp4: 384x640 1 tree, 7.6ms\n",
            "video 1/1 (37/312) /content/Untitled video - Made with Clipchamp.mp4: 384x640 1 tree, 11.0ms\n",
            "video 1/1 (38/312) /content/Untitled video - Made with Clipchamp.mp4: 384x640 1 tree, 7.4ms\n",
            "video 1/1 (39/312) /content/Untitled video - Made with Clipchamp.mp4: 384x640 1 tree, 8.0ms\n",
            "video 1/1 (40/312) /content/Untitled video - Made with Clipchamp.mp4: 384x640 1 tree, 7.8ms\n",
            "video 1/1 (41/312) /content/Untitled video - Made with Clipchamp.mp4: 384x640 1 tree, 7.3ms\n",
            "video 1/1 (42/312) /content/Untitled video - Made with Clipchamp.mp4: 384x640 1 tree, 7.7ms\n",
            "video 1/1 (43/312) /content/Untitled video - Made with Clipchamp.mp4: 384x640 1 tree, 7.7ms\n",
            "video 1/1 (44/312) /content/Untitled video - Made with Clipchamp.mp4: 384x640 1 tree, 7.7ms\n",
            "video 1/1 (45/312) /content/Untitled video - Made with Clipchamp.mp4: 384x640 1 tree, 7.7ms\n",
            "video 1/1 (46/312) /content/Untitled video - Made with Clipchamp.mp4: 384x640 1 tree, 7.3ms\n",
            "video 1/1 (47/312) /content/Untitled video - Made with Clipchamp.mp4: 384x640 1 tree, 7.2ms\n",
            "video 1/1 (48/312) /content/Untitled video - Made with Clipchamp.mp4: 384x640 1 tree, 7.3ms\n",
            "video 1/1 (49/312) /content/Untitled video - Made with Clipchamp.mp4: 384x640 1 tree, 7.4ms\n",
            "video 1/1 (50/312) /content/Untitled video - Made with Clipchamp.mp4: 384x640 1 tree, 7.4ms\n",
            "video 1/1 (51/312) /content/Untitled video - Made with Clipchamp.mp4: 384x640 1 tree, 8.7ms\n",
            "video 1/1 (52/312) /content/Untitled video - Made with Clipchamp.mp4: 384x640 1 tree, 7.4ms\n",
            "video 1/1 (53/312) /content/Untitled video - Made with Clipchamp.mp4: 384x640 1 tree, 7.4ms\n",
            "video 1/1 (54/312) /content/Untitled video - Made with Clipchamp.mp4: 384x640 1 tree, 7.5ms\n",
            "video 1/1 (55/312) /content/Untitled video - Made with Clipchamp.mp4: 384x640 1 tree, 7.5ms\n",
            "video 1/1 (56/312) /content/Untitled video - Made with Clipchamp.mp4: 384x640 1 tree, 7.5ms\n",
            "video 1/1 (57/312) /content/Untitled video - Made with Clipchamp.mp4: 384x640 1 tree, 7.7ms\n",
            "video 1/1 (58/312) /content/Untitled video - Made with Clipchamp.mp4: 384x640 1 tree, 8.6ms\n",
            "video 1/1 (59/312) /content/Untitled video - Made with Clipchamp.mp4: 384x640 1 tree, 7.5ms\n",
            "video 1/1 (60/312) /content/Untitled video - Made with Clipchamp.mp4: 384x640 1 tree, 7.5ms\n",
            "video 1/1 (61/312) /content/Untitled video - Made with Clipchamp.mp4: 384x640 1 tree, 8.6ms\n",
            "video 1/1 (62/312) /content/Untitled video - Made with Clipchamp.mp4: 384x640 1 tree, 7.3ms\n",
            "video 1/1 (63/312) /content/Untitled video - Made with Clipchamp.mp4: 384x640 1 tree, 7.4ms\n",
            "video 1/1 (64/312) /content/Untitled video - Made with Clipchamp.mp4: 384x640 1 tree, 7.8ms\n",
            "video 1/1 (65/312) /content/Untitled video - Made with Clipchamp.mp4: 384x640 1 tree, 8.6ms\n",
            "video 1/1 (66/312) /content/Untitled video - Made with Clipchamp.mp4: 384x640 1 tree, 7.3ms\n",
            "video 1/1 (67/312) /content/Untitled video - Made with Clipchamp.mp4: 384x640 1 tree, 7.7ms\n",
            "video 1/1 (68/312) /content/Untitled video - Made with Clipchamp.mp4: 384x640 1 tree, 8.8ms\n",
            "video 1/1 (69/312) /content/Untitled video - Made with Clipchamp.mp4: 384x640 2 trees, 7.8ms\n",
            "video 1/1 (70/312) /content/Untitled video - Made with Clipchamp.mp4: 384x640 2 trees, 8.1ms\n",
            "video 1/1 (71/312) /content/Untitled video - Made with Clipchamp.mp4: 384x640 2 trees, 7.5ms\n",
            "video 1/1 (72/312) /content/Untitled video - Made with Clipchamp.mp4: 384x640 2 trees, 8.3ms\n",
            "video 1/1 (73/312) /content/Untitled video - Made with Clipchamp.mp4: 384x640 2 trees, 7.6ms\n",
            "video 1/1 (74/312) /content/Untitled video - Made with Clipchamp.mp4: 384x640 2 trees, 7.6ms\n",
            "video 1/1 (75/312) /content/Untitled video - Made with Clipchamp.mp4: 384x640 2 trees, 7.6ms\n",
            "video 1/1 (76/312) /content/Untitled video - Made with Clipchamp.mp4: 384x640 2 trees, 7.7ms\n",
            "video 1/1 (77/312) /content/Untitled video - Made with Clipchamp.mp4: 384x640 2 trees, 7.5ms\n",
            "video 1/1 (78/312) /content/Untitled video - Made with Clipchamp.mp4: 384x640 2 trees, 7.4ms\n",
            "video 1/1 (79/312) /content/Untitled video - Made with Clipchamp.mp4: 384x640 2 trees, 7.5ms\n",
            "video 1/1 (80/312) /content/Untitled video - Made with Clipchamp.mp4: 384x640 2 trees, 8.6ms\n",
            "video 1/1 (81/312) /content/Untitled video - Made with Clipchamp.mp4: 384x640 2 trees, 11.9ms\n",
            "video 1/1 (82/312) /content/Untitled video - Made with Clipchamp.mp4: 384x640 2 trees, 8.4ms\n",
            "video 1/1 (83/312) /content/Untitled video - Made with Clipchamp.mp4: 384x640 2 trees, 7.9ms\n",
            "video 1/1 (84/312) /content/Untitled video - Made with Clipchamp.mp4: 384x640 2 trees, 7.4ms\n",
            "video 1/1 (85/312) /content/Untitled video - Made with Clipchamp.mp4: 384x640 2 trees, 7.6ms\n",
            "video 1/1 (86/312) /content/Untitled video - Made with Clipchamp.mp4: 384x640 2 trees, 7.8ms\n",
            "video 1/1 (87/312) /content/Untitled video - Made with Clipchamp.mp4: 384x640 2 trees, 7.6ms\n",
            "video 1/1 (88/312) /content/Untitled video - Made with Clipchamp.mp4: 384x640 2 trees, 8.1ms\n",
            "video 1/1 (89/312) /content/Untitled video - Made with Clipchamp.mp4: 384x640 2 trees, 10.3ms\n",
            "video 1/1 (90/312) /content/Untitled video - Made with Clipchamp.mp4: 384x640 2 trees, 7.7ms\n",
            "video 1/1 (91/312) /content/Untitled video - Made with Clipchamp.mp4: 384x640 2 trees, 7.5ms\n",
            "video 1/1 (92/312) /content/Untitled video - Made with Clipchamp.mp4: 384x640 2 trees, 8.4ms\n",
            "video 1/1 (93/312) /content/Untitled video - Made with Clipchamp.mp4: 384x640 2 trees, 8.9ms\n",
            "video 1/1 (94/312) /content/Untitled video - Made with Clipchamp.mp4: 384x640 2 trees, 8.9ms\n",
            "video 1/1 (95/312) /content/Untitled video - Made with Clipchamp.mp4: 384x640 2 trees, 10.4ms\n",
            "video 1/1 (96/312) /content/Untitled video - Made with Clipchamp.mp4: 384x640 2 trees, 8.4ms\n",
            "video 1/1 (97/312) /content/Untitled video - Made with Clipchamp.mp4: 384x640 2 trees, 9.2ms\n",
            "video 1/1 (98/312) /content/Untitled video - Made with Clipchamp.mp4: 384x640 2 trees, 8.4ms\n",
            "video 1/1 (99/312) /content/Untitled video - Made with Clipchamp.mp4: 384x640 2 trees, 8.1ms\n",
            "video 1/1 (100/312) /content/Untitled video - Made with Clipchamp.mp4: 384x640 2 trees, 8.6ms\n",
            "video 1/1 (101/312) /content/Untitled video - Made with Clipchamp.mp4: 384x640 2 trees, 8.4ms\n",
            "video 1/1 (102/312) /content/Untitled video - Made with Clipchamp.mp4: 384x640 2 trees, 8.4ms\n",
            "video 1/1 (103/312) /content/Untitled video - Made with Clipchamp.mp4: 384x640 2 trees, 8.0ms\n",
            "video 1/1 (104/312) /content/Untitled video - Made with Clipchamp.mp4: 384x640 2 trees, 8.1ms\n",
            "video 1/1 (105/312) /content/Untitled video - Made with Clipchamp.mp4: 384x640 2 trees, 8.4ms\n",
            "video 1/1 (106/312) /content/Untitled video - Made with Clipchamp.mp4: 384x640 2 trees, 8.4ms\n",
            "video 1/1 (107/312) /content/Untitled video - Made with Clipchamp.mp4: 384x640 2 trees, 8.0ms\n",
            "video 1/1 (108/312) /content/Untitled video - Made with Clipchamp.mp4: 384x640 2 trees, 11.5ms\n",
            "video 1/1 (109/312) /content/Untitled video - Made with Clipchamp.mp4: 384x640 2 trees, 7.7ms\n",
            "video 1/1 (110/312) /content/Untitled video - Made with Clipchamp.mp4: 384x640 2 trees, 8.0ms\n",
            "video 1/1 (111/312) /content/Untitled video - Made with Clipchamp.mp4: 384x640 2 trees, 7.6ms\n",
            "video 1/1 (112/312) /content/Untitled video - Made with Clipchamp.mp4: 384x640 2 trees, 8.3ms\n",
            "video 1/1 (113/312) /content/Untitled video - Made with Clipchamp.mp4: 384x640 2 trees, 7.4ms\n",
            "video 1/1 (114/312) /content/Untitled video - Made with Clipchamp.mp4: 384x640 2 trees, 11.1ms\n",
            "video 1/1 (115/312) /content/Untitled video - Made with Clipchamp.mp4: 384x640 2 trees, 7.8ms\n",
            "video 1/1 (116/312) /content/Untitled video - Made with Clipchamp.mp4: 384x640 2 trees, 8.2ms\n",
            "video 1/1 (117/312) /content/Untitled video - Made with Clipchamp.mp4: 384x640 2 trees, 8.1ms\n",
            "video 1/1 (118/312) /content/Untitled video - Made with Clipchamp.mp4: 384x640 2 trees, 7.7ms\n",
            "video 1/1 (119/312) /content/Untitled video - Made with Clipchamp.mp4: 384x640 2 trees, 7.6ms\n",
            "video 1/1 (120/312) /content/Untitled video - Made with Clipchamp.mp4: 384x640 2 trees, 7.7ms\n",
            "video 1/1 (121/312) /content/Untitled video - Made with Clipchamp.mp4: 384x640 2 trees, 8.1ms\n",
            "video 1/1 (122/312) /content/Untitled video - Made with Clipchamp.mp4: 384x640 2 trees, 7.8ms\n",
            "video 1/1 (123/312) /content/Untitled video - Made with Clipchamp.mp4: 384x640 2 trees, 10.2ms\n",
            "video 1/1 (124/312) /content/Untitled video - Made with Clipchamp.mp4: 384x640 2 trees, 8.1ms\n",
            "video 1/1 (125/312) /content/Untitled video - Made with Clipchamp.mp4: 384x640 2 trees, 8.0ms\n",
            "video 1/1 (126/312) /content/Untitled video - Made with Clipchamp.mp4: 384x640 2 trees, 7.6ms\n",
            "video 1/1 (127/312) /content/Untitled video - Made with Clipchamp.mp4: 384x640 2 trees, 9.1ms\n",
            "video 1/1 (128/312) /content/Untitled video - Made with Clipchamp.mp4: 384x640 2 trees, 8.2ms\n",
            "video 1/1 (129/312) /content/Untitled video - Made with Clipchamp.mp4: 384x640 2 trees, 8.5ms\n",
            "video 1/1 (130/312) /content/Untitled video - Made with Clipchamp.mp4: 384x640 2 trees, 7.9ms\n",
            "video 1/1 (131/312) /content/Untitled video - Made with Clipchamp.mp4: 384x640 2 trees, 7.5ms\n",
            "video 1/1 (132/312) /content/Untitled video - Made with Clipchamp.mp4: 384x640 2 trees, 7.9ms\n",
            "video 1/1 (133/312) /content/Untitled video - Made with Clipchamp.mp4: 384x640 2 trees, 7.3ms\n",
            "video 1/1 (134/312) /content/Untitled video - Made with Clipchamp.mp4: 384x640 2 trees, 7.3ms\n",
            "video 1/1 (135/312) /content/Untitled video - Made with Clipchamp.mp4: 384x640 2 trees, 7.9ms\n",
            "video 1/1 (136/312) /content/Untitled video - Made with Clipchamp.mp4: 384x640 2 trees, 7.1ms\n",
            "video 1/1 (137/312) /content/Untitled video - Made with Clipchamp.mp4: 384x640 2 trees, 7.2ms\n",
            "video 1/1 (138/312) /content/Untitled video - Made with Clipchamp.mp4: 384x640 2 trees, 17.5ms\n",
            "video 1/1 (139/312) /content/Untitled video - Made with Clipchamp.mp4: 384x640 2 trees, 7.5ms\n",
            "video 1/1 (140/312) /content/Untitled video - Made with Clipchamp.mp4: 384x640 2 trees, 7.6ms\n",
            "video 1/1 (141/312) /content/Untitled video - Made with Clipchamp.mp4: 384x640 1 tree, 7.6ms\n",
            "video 1/1 (142/312) /content/Untitled video - Made with Clipchamp.mp4: 384x640 1 tree, 7.5ms\n",
            "video 1/1 (143/312) /content/Untitled video - Made with Clipchamp.mp4: 384x640 1 tree, 7.5ms\n",
            "video 1/1 (144/312) /content/Untitled video - Made with Clipchamp.mp4: 384x640 2 trees, 7.5ms\n",
            "video 1/1 (145/312) /content/Untitled video - Made with Clipchamp.mp4: 384x640 2 trees, 7.7ms\n",
            "video 1/1 (146/312) /content/Untitled video - Made with Clipchamp.mp4: 384x640 2 trees, 7.9ms\n",
            "video 1/1 (147/312) /content/Untitled video - Made with Clipchamp.mp4: 384x640 3 trees, 8.2ms\n",
            "video 1/1 (148/312) /content/Untitled video - Made with Clipchamp.mp4: 384x640 3 trees, 7.6ms\n",
            "video 1/1 (149/312) /content/Untitled video - Made with Clipchamp.mp4: 384x640 2 trees, 13.3ms\n",
            "video 1/1 (150/312) /content/Untitled video - Made with Clipchamp.mp4: 384x640 2 trees, 7.5ms\n",
            "video 1/1 (151/312) /content/Untitled video - Made with Clipchamp.mp4: 384x640 2 trees, 7.5ms\n",
            "video 1/1 (152/312) /content/Untitled video - Made with Clipchamp.mp4: 384x640 2 trees, 7.5ms\n",
            "video 1/1 (153/312) /content/Untitled video - Made with Clipchamp.mp4: 384x640 2 trees, 7.7ms\n",
            "video 1/1 (154/312) /content/Untitled video - Made with Clipchamp.mp4: 384x640 2 trees, 7.5ms\n",
            "video 1/1 (155/312) /content/Untitled video - Made with Clipchamp.mp4: 384x640 2 trees, 7.7ms\n",
            "video 1/1 (156/312) /content/Untitled video - Made with Clipchamp.mp4: 384x640 2 trees, 7.5ms\n",
            "video 1/1 (157/312) /content/Untitled video - Made with Clipchamp.mp4: 384x640 2 trees, 8.2ms\n",
            "video 1/1 (158/312) /content/Untitled video - Made with Clipchamp.mp4: 384x640 2 trees, 8.0ms\n",
            "video 1/1 (159/312) /content/Untitled video - Made with Clipchamp.mp4: 384x640 1 tree, 8.5ms\n",
            "video 1/1 (160/312) /content/Untitled video - Made with Clipchamp.mp4: 384x640 1 tree, 8.1ms\n",
            "video 1/1 (161/312) /content/Untitled video - Made with Clipchamp.mp4: 384x640 1 tree, 7.8ms\n",
            "video 1/1 (162/312) /content/Untitled video - Made with Clipchamp.mp4: 384x640 1 tree, 10.8ms\n",
            "video 1/1 (163/312) /content/Untitled video - Made with Clipchamp.mp4: 384x640 1 tree, 7.2ms\n",
            "video 1/1 (164/312) /content/Untitled video - Made with Clipchamp.mp4: 384x640 1 tree, 7.5ms\n",
            "video 1/1 (165/312) /content/Untitled video - Made with Clipchamp.mp4: 384x640 1 tree, 7.7ms\n",
            "video 1/1 (166/312) /content/Untitled video - Made with Clipchamp.mp4: 384x640 1 tree, 8.3ms\n",
            "video 1/1 (167/312) /content/Untitled video - Made with Clipchamp.mp4: 384x640 2 trees, 7.6ms\n",
            "video 1/1 (168/312) /content/Untitled video - Made with Clipchamp.mp4: 384x640 2 trees, 7.7ms\n",
            "video 1/1 (169/312) /content/Untitled video - Made with Clipchamp.mp4: 384x640 2 trees, 7.9ms\n",
            "video 1/1 (170/312) /content/Untitled video - Made with Clipchamp.mp4: 384x640 2 trees, 6.9ms\n",
            "video 1/1 (171/312) /content/Untitled video - Made with Clipchamp.mp4: 384x640 1 tree, 7.3ms\n",
            "video 1/1 (172/312) /content/Untitled video - Made with Clipchamp.mp4: 384x640 1 tree, 7.7ms\n",
            "video 1/1 (173/312) /content/Untitled video - Made with Clipchamp.mp4: 384x640 2 trees, 7.9ms\n",
            "video 1/1 (174/312) /content/Untitled video - Made with Clipchamp.mp4: 384x640 2 trees, 7.2ms\n",
            "video 1/1 (175/312) /content/Untitled video - Made with Clipchamp.mp4: 384x640 1 tree, 7.5ms\n",
            "video 1/1 (176/312) /content/Untitled video - Made with Clipchamp.mp4: 384x640 2 trees, 8.3ms\n",
            "video 1/1 (177/312) /content/Untitled video - Made with Clipchamp.mp4: 384x640 2 trees, 7.4ms\n",
            "video 1/1 (178/312) /content/Untitled video - Made with Clipchamp.mp4: 384x640 2 trees, 7.1ms\n",
            "video 1/1 (179/312) /content/Untitled video - Made with Clipchamp.mp4: 384x640 2 trees, 7.4ms\n",
            "video 1/1 (180/312) /content/Untitled video - Made with Clipchamp.mp4: 384x640 2 trees, 7.2ms\n",
            "video 1/1 (181/312) /content/Untitled video - Made with Clipchamp.mp4: 384x640 2 trees, 9.7ms\n",
            "video 1/1 (182/312) /content/Untitled video - Made with Clipchamp.mp4: 384x640 2 trees, 7.3ms\n",
            "video 1/1 (183/312) /content/Untitled video - Made with Clipchamp.mp4: 384x640 2 trees, 7.7ms\n",
            "video 1/1 (184/312) /content/Untitled video - Made with Clipchamp.mp4: 384x640 2 trees, 10.9ms\n",
            "video 1/1 (185/312) /content/Untitled video - Made with Clipchamp.mp4: 384x640 1 tree, 7.5ms\n",
            "video 1/1 (186/312) /content/Untitled video - Made with Clipchamp.mp4: 384x640 2 trees, 9.2ms\n",
            "video 1/1 (187/312) /content/Untitled video - Made with Clipchamp.mp4: 384x640 2 trees, 7.4ms\n",
            "video 1/1 (188/312) /content/Untitled video - Made with Clipchamp.mp4: 384x640 2 trees, 7.5ms\n",
            "video 1/1 (189/312) /content/Untitled video - Made with Clipchamp.mp4: 384x640 1 tree, 7.4ms\n",
            "video 1/1 (190/312) /content/Untitled video - Made with Clipchamp.mp4: 384x640 1 tree, 7.5ms\n",
            "video 1/1 (191/312) /content/Untitled video - Made with Clipchamp.mp4: 384x640 1 tree, 7.5ms\n",
            "video 1/1 (192/312) /content/Untitled video - Made with Clipchamp.mp4: 384x640 1 tree, 10.8ms\n",
            "video 1/1 (193/312) /content/Untitled video - Made with Clipchamp.mp4: 384x640 1 tree, 7.7ms\n",
            "video 1/1 (194/312) /content/Untitled video - Made with Clipchamp.mp4: 384x640 1 tree, 7.6ms\n",
            "video 1/1 (195/312) /content/Untitled video - Made with Clipchamp.mp4: 384x640 1 tree, 8.7ms\n",
            "video 1/1 (196/312) /content/Untitled video - Made with Clipchamp.mp4: 384x640 1 tree, 8.7ms\n",
            "video 1/1 (197/312) /content/Untitled video - Made with Clipchamp.mp4: 384x640 1 tree, 8.2ms\n",
            "video 1/1 (198/312) /content/Untitled video - Made with Clipchamp.mp4: 384x640 1 tree, 7.7ms\n",
            "video 1/1 (199/312) /content/Untitled video - Made with Clipchamp.mp4: 384x640 1 tree, 8.7ms\n",
            "video 1/1 (200/312) /content/Untitled video - Made with Clipchamp.mp4: 384x640 1 tree, 7.3ms\n",
            "video 1/1 (201/312) /content/Untitled video - Made with Clipchamp.mp4: 384x640 2 trees, 9.4ms\n",
            "video 1/1 (202/312) /content/Untitled video - Made with Clipchamp.mp4: 384x640 2 trees, 7.8ms\n",
            "video 1/1 (203/312) /content/Untitled video - Made with Clipchamp.mp4: 384x640 1 tree, 8.0ms\n",
            "video 1/1 (204/312) /content/Untitled video - Made with Clipchamp.mp4: 384x640 1 tree, 7.7ms\n",
            "video 1/1 (205/312) /content/Untitled video - Made with Clipchamp.mp4: 384x640 2 trees, 7.7ms\n",
            "video 1/1 (206/312) /content/Untitled video - Made with Clipchamp.mp4: 384x640 2 trees, 7.5ms\n",
            "video 1/1 (207/312) /content/Untitled video - Made with Clipchamp.mp4: 384x640 1 tree, 7.8ms\n",
            "video 1/1 (208/312) /content/Untitled video - Made with Clipchamp.mp4: 384x640 2 trees, 7.8ms\n",
            "video 1/1 (209/312) /content/Untitled video - Made with Clipchamp.mp4: 384x640 3 trees, 10.7ms\n",
            "video 1/1 (210/312) /content/Untitled video - Made with Clipchamp.mp4: 384x640 2 trees, 7.6ms\n",
            "video 1/1 (211/312) /content/Untitled video - Made with Clipchamp.mp4: 384x640 3 trees, 7.8ms\n",
            "video 1/1 (212/312) /content/Untitled video - Made with Clipchamp.mp4: 384x640 2 trees, 8.3ms\n",
            "video 1/1 (213/312) /content/Untitled video - Made with Clipchamp.mp4: 384x640 2 trees, 8.4ms\n",
            "video 1/1 (214/312) /content/Untitled video - Made with Clipchamp.mp4: 384x640 1 tree, 7.9ms\n",
            "video 1/1 (215/312) /content/Untitled video - Made with Clipchamp.mp4: 384x640 2 trees, 7.9ms\n",
            "video 1/1 (216/312) /content/Untitled video - Made with Clipchamp.mp4: 384x640 1 tree, 7.9ms\n",
            "video 1/1 (217/312) /content/Untitled video - Made with Clipchamp.mp4: 384x640 1 tree, 9.8ms\n",
            "video 1/1 (218/312) /content/Untitled video - Made with Clipchamp.mp4: 384x640 1 tree, 7.7ms\n",
            "video 1/1 (219/312) /content/Untitled video - Made with Clipchamp.mp4: 384x640 1 tree, 7.8ms\n",
            "video 1/1 (220/312) /content/Untitled video - Made with Clipchamp.mp4: 384x640 1 tree, 7.8ms\n",
            "video 1/1 (221/312) /content/Untitled video - Made with Clipchamp.mp4: 384x640 1 tree, 7.9ms\n",
            "video 1/1 (222/312) /content/Untitled video - Made with Clipchamp.mp4: 384x640 1 tree, 7.9ms\n",
            "video 1/1 (223/312) /content/Untitled video - Made with Clipchamp.mp4: 384x640 1 tree, 8.1ms\n",
            "video 1/1 (224/312) /content/Untitled video - Made with Clipchamp.mp4: 384x640 1 tree, 7.9ms\n",
            "video 1/1 (225/312) /content/Untitled video - Made with Clipchamp.mp4: 384x640 1 tree, 7.7ms\n",
            "video 1/1 (226/312) /content/Untitled video - Made with Clipchamp.mp4: 384x640 1 tree, 8.6ms\n",
            "video 1/1 (227/312) /content/Untitled video - Made with Clipchamp.mp4: 384x640 1 tree, 8.1ms\n",
            "video 1/1 (228/312) /content/Untitled video - Made with Clipchamp.mp4: 384x640 1 tree, 10.7ms\n",
            "video 1/1 (229/312) /content/Untitled video - Made with Clipchamp.mp4: 384x640 1 tree, 7.7ms\n",
            "video 1/1 (230/312) /content/Untitled video - Made with Clipchamp.mp4: 384x640 1 tree, 7.8ms\n",
            "video 1/1 (231/312) /content/Untitled video - Made with Clipchamp.mp4: 384x640 1 tree, 8.6ms\n",
            "video 1/1 (232/312) /content/Untitled video - Made with Clipchamp.mp4: 384x640 1 tree, 8.3ms\n",
            "video 1/1 (233/312) /content/Untitled video - Made with Clipchamp.mp4: 384x640 1 tree, 8.8ms\n",
            "video 1/1 (234/312) /content/Untitled video - Made with Clipchamp.mp4: 384x640 1 tree, 7.8ms\n",
            "video 1/1 (235/312) /content/Untitled video - Made with Clipchamp.mp4: 384x640 2 trees, 9.3ms\n",
            "video 1/1 (236/312) /content/Untitled video - Made with Clipchamp.mp4: 384x640 1 tree, 7.9ms\n",
            "video 1/1 (237/312) /content/Untitled video - Made with Clipchamp.mp4: 384x640 1 tree, 7.7ms\n",
            "video 1/1 (238/312) /content/Untitled video - Made with Clipchamp.mp4: 384x640 2 trees, 8.6ms\n",
            "video 1/1 (239/312) /content/Untitled video - Made with Clipchamp.mp4: 384x640 1 tree, 7.9ms\n",
            "video 1/1 (240/312) /content/Untitled video - Made with Clipchamp.mp4: 384x640 1 tree, 8.1ms\n",
            "video 1/1 (241/312) /content/Untitled video - Made with Clipchamp.mp4: 384x640 1 tree, 8.2ms\n",
            "video 1/1 (242/312) /content/Untitled video - Made with Clipchamp.mp4: 384x640 1 tree, 7.9ms\n",
            "video 1/1 (243/312) /content/Untitled video - Made with Clipchamp.mp4: 384x640 1 tree, 7.4ms\n",
            "video 1/1 (244/312) /content/Untitled video - Made with Clipchamp.mp4: 384x640 1 tree, 7.7ms\n",
            "video 1/1 (245/312) /content/Untitled video - Made with Clipchamp.mp4: 384x640 1 tree, 9.1ms\n",
            "video 1/1 (246/312) /content/Untitled video - Made with Clipchamp.mp4: 384x640 1 tree, 7.7ms\n",
            "video 1/1 (247/312) /content/Untitled video - Made with Clipchamp.mp4: 384x640 1 tree, 8.2ms\n",
            "video 1/1 (248/312) /content/Untitled video - Made with Clipchamp.mp4: 384x640 1 tree, 8.4ms\n",
            "video 1/1 (249/312) /content/Untitled video - Made with Clipchamp.mp4: 384x640 1 tree, 7.9ms\n",
            "video 1/1 (250/312) /content/Untitled video - Made with Clipchamp.mp4: 384x640 1 tree, 11.8ms\n",
            "video 1/1 (251/312) /content/Untitled video - Made with Clipchamp.mp4: 384x640 1 tree, 7.8ms\n",
            "video 1/1 (252/312) /content/Untitled video - Made with Clipchamp.mp4: 384x640 1 tree, 7.6ms\n",
            "video 1/1 (253/312) /content/Untitled video - Made with Clipchamp.mp4: 384x640 1 tree, 7.6ms\n",
            "video 1/1 (254/312) /content/Untitled video - Made with Clipchamp.mp4: 384x640 1 tree, 8.7ms\n",
            "video 1/1 (255/312) /content/Untitled video - Made with Clipchamp.mp4: 384x640 1 tree, 7.6ms\n",
            "video 1/1 (256/312) /content/Untitled video - Made with Clipchamp.mp4: 384x640 1 tree, 9.7ms\n",
            "video 1/1 (257/312) /content/Untitled video - Made with Clipchamp.mp4: 384x640 1 tree, 7.8ms\n",
            "video 1/1 (258/312) /content/Untitled video - Made with Clipchamp.mp4: 384x640 1 tree, 7.7ms\n",
            "video 1/1 (259/312) /content/Untitled video - Made with Clipchamp.mp4: 384x640 1 tree, 7.9ms\n",
            "video 1/1 (260/312) /content/Untitled video - Made with Clipchamp.mp4: 384x640 1 tree, 7.6ms\n",
            "video 1/1 (261/312) /content/Untitled video - Made with Clipchamp.mp4: 384x640 1 tree, 7.6ms\n",
            "video 1/1 (262/312) /content/Untitled video - Made with Clipchamp.mp4: 384x640 1 tree, 7.7ms\n",
            "video 1/1 (263/312) /content/Untitled video - Made with Clipchamp.mp4: 384x640 1 tree, 7.6ms\n",
            "video 1/1 (264/312) /content/Untitled video - Made with Clipchamp.mp4: 384x640 1 tree, 8.3ms\n",
            "video 1/1 (265/312) /content/Untitled video - Made with Clipchamp.mp4: 384x640 1 tree, 7.8ms\n",
            "video 1/1 (266/312) /content/Untitled video - Made with Clipchamp.mp4: 384x640 1 tree, 8.4ms\n",
            "video 1/1 (267/312) /content/Untitled video - Made with Clipchamp.mp4: 384x640 1 tree, 7.7ms\n",
            "video 1/1 (268/312) /content/Untitled video - Made with Clipchamp.mp4: 384x640 1 tree, 9.4ms\n",
            "video 1/1 (269/312) /content/Untitled video - Made with Clipchamp.mp4: 384x640 1 tree, 7.7ms\n",
            "video 1/1 (270/312) /content/Untitled video - Made with Clipchamp.mp4: 384x640 1 tree, 7.5ms\n",
            "video 1/1 (271/312) /content/Untitled video - Made with Clipchamp.mp4: 384x640 1 tree, 7.8ms\n",
            "video 1/1 (272/312) /content/Untitled video - Made with Clipchamp.mp4: 384x640 1 tree, 11.0ms\n",
            "video 1/1 (273/312) /content/Untitled video - Made with Clipchamp.mp4: 384x640 1 tree, 10.3ms\n",
            "video 1/1 (274/312) /content/Untitled video - Made with Clipchamp.mp4: 384x640 1 tree, 14.3ms\n",
            "video 1/1 (275/312) /content/Untitled video - Made with Clipchamp.mp4: 384x640 1 tree, 8.7ms\n",
            "video 1/1 (276/312) /content/Untitled video - Made with Clipchamp.mp4: 384x640 1 tree, 9.2ms\n",
            "video 1/1 (277/312) /content/Untitled video - Made with Clipchamp.mp4: 384x640 1 tree, 16.0ms\n",
            "video 1/1 (278/312) /content/Untitled video - Made with Clipchamp.mp4: 384x640 1 tree, 15.5ms\n",
            "video 1/1 (279/312) /content/Untitled video - Made with Clipchamp.mp4: 384x640 1 tree, 9.3ms\n",
            "video 1/1 (280/312) /content/Untitled video - Made with Clipchamp.mp4: 384x640 1 tree, 16.7ms\n",
            "video 1/1 (281/312) /content/Untitled video - Made with Clipchamp.mp4: 384x640 1 tree, 9.7ms\n",
            "video 1/1 (282/312) /content/Untitled video - Made with Clipchamp.mp4: 384x640 1 tree, 8.7ms\n",
            "video 1/1 (283/312) /content/Untitled video - Made with Clipchamp.mp4: 384x640 1 tree, 9.8ms\n",
            "video 1/1 (284/312) /content/Untitled video - Made with Clipchamp.mp4: 384x640 1 tree, 9.9ms\n",
            "video 1/1 (285/312) /content/Untitled video - Made with Clipchamp.mp4: 384x640 1 tree, 8.3ms\n",
            "video 1/1 (286/312) /content/Untitled video - Made with Clipchamp.mp4: 384x640 1 tree, 9.2ms\n",
            "video 1/1 (287/312) /content/Untitled video - Made with Clipchamp.mp4: 384x640 1 tree, 9.4ms\n",
            "video 1/1 (288/312) /content/Untitled video - Made with Clipchamp.mp4: 384x640 1 tree, 8.1ms\n",
            "video 1/1 (289/312) /content/Untitled video - Made with Clipchamp.mp4: 384x640 1 tree, 7.9ms\n",
            "video 1/1 (290/312) /content/Untitled video - Made with Clipchamp.mp4: 384x640 1 tree, 8.3ms\n",
            "video 1/1 (291/312) /content/Untitled video - Made with Clipchamp.mp4: 384x640 1 tree, 8.5ms\n",
            "video 1/1 (292/312) /content/Untitled video - Made with Clipchamp.mp4: 384x640 1 tree, 10.6ms\n",
            "video 1/1 (293/312) /content/Untitled video - Made with Clipchamp.mp4: 384x640 1 tree, 8.3ms\n",
            "video 1/1 (294/312) /content/Untitled video - Made with Clipchamp.mp4: 384x640 1 tree, 8.0ms\n",
            "video 1/1 (295/312) /content/Untitled video - Made with Clipchamp.mp4: 384x640 1 tree, 8.8ms\n",
            "video 1/1 (296/312) /content/Untitled video - Made with Clipchamp.mp4: 384x640 1 tree, 12.4ms\n",
            "video 1/1 (297/312) /content/Untitled video - Made with Clipchamp.mp4: 384x640 1 tree, 12.0ms\n",
            "video 1/1 (298/312) /content/Untitled video - Made with Clipchamp.mp4: 384x640 1 tree, 17.6ms\n",
            "video 1/1 (299/312) /content/Untitled video - Made with Clipchamp.mp4: 384x640 1 tree, 11.8ms\n",
            "video 1/1 (300/312) /content/Untitled video - Made with Clipchamp.mp4: 384x640 1 tree, 9.1ms\n",
            "video 1/1 (301/312) /content/Untitled video - Made with Clipchamp.mp4: 384x640 1 tree, 12.1ms\n",
            "video 1/1 (302/312) /content/Untitled video - Made with Clipchamp.mp4: 384x640 1 tree, 12.1ms\n",
            "video 1/1 (303/312) /content/Untitled video - Made with Clipchamp.mp4: 384x640 1 tree, 8.7ms\n",
            "video 1/1 (304/312) /content/Untitled video - Made with Clipchamp.mp4: 384x640 1 tree, 10.6ms\n",
            "video 1/1 (305/312) /content/Untitled video - Made with Clipchamp.mp4: 384x640 1 tree, 10.0ms\n",
            "video 1/1 (306/312) /content/Untitled video - Made with Clipchamp.mp4: 384x640 1 tree, 8.7ms\n",
            "video 1/1 (307/312) /content/Untitled video - Made with Clipchamp.mp4: 384x640 1 tree, 12.3ms\n",
            "video 1/1 (308/312) /content/Untitled video - Made with Clipchamp.mp4: 384x640 1 tree, 9.2ms\n",
            "video 1/1 (309/312) /content/Untitled video - Made with Clipchamp.mp4: 384x640 1 tree, 9.1ms\n",
            "video 1/1 (310/312) /content/Untitled video - Made with Clipchamp.mp4: 384x640 1 tree, 8.8ms\n",
            "video 1/1 (311/312) /content/Untitled video - Made with Clipchamp.mp4: 384x640 2 trees, 13.7ms\n",
            "video 1/1 (312/312) /content/Untitled video - Made with Clipchamp.mp4: 384x640 1 tree, 8.2ms\n",
            "Speed: 1.8ms preprocess, 8.8ms inference, 3.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Results saved to \u001b[1mruns/detect/predict4\u001b[0m\n",
            "💡 Learn more at https://docs.ultralytics.com/modes/predict\n"
          ]
        }
      ],
      "source": [
        "!yolo detect predict model=/content/gdrive/MyDrive/orchad-crop/runs/detect/train14/weights/best.pt source='/content/Untitled video - Made with Clipchamp.mp4'"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
